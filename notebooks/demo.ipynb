{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Modal RAG Demo\n",
    "This notebook is to run each step within the Multi-Modal RAG workflow in isolation primarily for debugging and development purposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "from IPython.display import Markdown, display\n",
    "import ipywidgets as widgets\n",
    "import logging\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.multi_modal_llms.azure_openai import AzureOpenAIMultiModal\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "\n",
    "import src.tools as tools\n",
    "importlib.reload(tools)\n",
    "from src.tools import get_index_docs_summary, MultimodalQueryEngine, display_query_and_multimodal_response, download_sharepoint_files\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME\")\n",
    "similarity_top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    model=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "    deployment_name=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "azure_openai_mm_llm = AzureOpenAIMultiModal(\n",
    "    engine=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    model=AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME,\n",
    "    max_new_tokens=4096,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_base=AZURE_OPENAI_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files in the LOCAL_BASE_DIR\n",
    "document_url_dict = download_sharepoint_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build or load indexes and summaries\n",
    "indexes, document_summary_dict = get_index_docs_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_summary_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Input your query\n",
    "query_widget = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Type your query here...\",\n",
    "    description=\"Query:\",\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(query_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Processing the query\n",
    "query = \"in terms of scaling AI/ML what percentage of executives disagree with this statement?\"\n",
    "if query_widget.value:\n",
    "    query = query_widget.value\n",
    "\n",
    "# Create the prompt\n",
    "prompt = (\n",
    "    f\"Given the query '{query}', determine the most appropriate index (key) in the dictionary \"\n",
    "    f\"based on the description (value) that corresponds best to the query. \"\n",
    "    f\"Return only the index (key) as the output, nothing else. \"\n",
    "    f\"Options: {', '.join([f'Index: {key}, Description: {value}' for key, value in document_summary_dict.items()])}\"\n",
    "    )\n",
    "\n",
    "# Call the LLM endpoint with the prompt\n",
    "selected_index = llm.complete(prompt).text.strip()\n",
    "print(selected_index)\n",
    "\n",
    "index = indexes[selected_index]\n",
    "\n",
    "# Create and initialize the query engine\n",
    "query_engine = MultimodalQueryEngine(\n",
    "    retriever=index.as_retriever(\n",
    "        vector_store_query_mode=VectorStoreQueryMode.DEFAULT, similarity_top_k=similarity_top_k \n",
    "    ),\n",
    "    multi_modal_llm=azure_openai_mm_llm,\n",
    ")\n",
    "\n",
    "# Execute the query\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Display the response\n",
    "display(Markdown(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Display the sources (1)\n",
    "display_query_and_multimodal_response(response, 8, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Display the sources (2)\n",
    "print(f\"Retrieved document:\\n{selected_index}\\n\")\n",
    "\n",
    "print(f\"Url to the document:\")\n",
    "print(f\"{document_url_dict[selected_index]}\\n\")\n",
    "\n",
    "print(f\"Summary of the document:\")\n",
    "display(Markdown(document_summary_dict[selected_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Display the sources (3)\n",
    "logger.info(\"\\nSource Nodes:\")\n",
    "for node in response.source_nodes:\n",
    "    print(f\"\\nPage Number: {node.metadata['page_num']}\")\n",
    "    print(f\"Text Content Length: {len(node.text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Retrieval\n",
    "The token retrieved in this step can be used to send POST requests to the backend API using tools such as FastAPI Swagger for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.core.exceptions import AzureError\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "tenant_id = os.getenv(\"TENANT_ID\")\n",
    "client_id = os.getenv(\"APP_REGISTRATION_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"APP_REGISTRATION_CLIENT_SECRET\")\n",
    "resource_scope = os.getenv(\"APP_REGISTRATION_RESOURCE_SCOPE\")\n",
    "\n",
    "# Get token\n",
    "credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
    "\n",
    "try:\n",
    "    token = credential.get_token(resource_scope)\n",
    "except AzureError as e:\n",
    "    print(\"Failed to get token:\", str(e))\n",
    "\n",
    "print(token.token) # use this token to authenticate before sending requests to the API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
